{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Titanic Passenger Clusters with Mean Shift\n",
    "\n",
    "In this dataset, we will use the famous Titanic Passengers dataset to test out a mean shift model, and see if the model's clusters can give us any insight into what determined if a passenger survuved or died.\n",
    "\n",
    "Let's start by importing the linraries we will be using and loading the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.cluster import MeanShift, KMeans\n",
    "from sklearn import preprocessing, model_selection\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "'''\n",
    "Pclass Passenger Class (1 = 1st; 2 = 2nd; 3 = 3rd)\n",
    "survival Survival (0 = No; 1 = Yes)\n",
    "name Name\n",
    "sex Sex\n",
    "age Age\n",
    "sibsp Number of Siblings/Spouses Aboard\n",
    "parch Number of Parents/Children Aboard\n",
    "ticket Ticket Number\n",
    "fare Passenger Fare (British pound)\n",
    "cabin Cabin\n",
    "embarked Port of Embarkation (C = Cherbourg; Q = Queenstown; S = Southampton)\n",
    "boat Lifeboat\n",
    "body Body Identification Number\n",
    "home.dest Home/Destination\n",
    "'''\n",
    "\n",
    "df = pd.read_excel('titanic.xls')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make a copy of the df so that we can see values as text instead of ints at the end. We must convert qualifiable values to ints for the model, and wil use the copy of the df to return the text values after. We will make a function for this conversion below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_df = pd.DataFrame.copy(df)\n",
    "df.drop(['body','name'], 1, inplace=True)\n",
    "df.fillna(0,inplace=True)\n",
    "\n",
    "def handle_non_numerical_data(df):\n",
    "    \n",
    "    columns = df.columns.values\n",
    "\n",
    "    for column in columns:\n",
    "        text_digit_vals = {}\n",
    "        def convert_to_int(val):\n",
    "            return text_digit_vals[val]\n",
    "\n",
    "        if df[column].dtype != np.int64 and df[column].dtype != np.float64:\n",
    "            \n",
    "            column_contents = df[column].values.tolist()\n",
    "            unique_elements = set(column_contents) \n",
    "            x = 0\n",
    "            for unique in unique_elements:\n",
    "                if unique not in text_digit_vals:\n",
    "                    text_digit_vals[unique] = x\n",
    "                    x+=1 \n",
    "            df[column] = list(map(convert_to_int,df[column]))\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now run the conversion function on the df, and drop un-needed fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = handle_non_numerical_data(df)\n",
    "df.drop(['ticket','home.dest'], 1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will create and train our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MeanShift(bandwidth=None, bin_seeding=False, cluster_all=True, min_bin_freq=1,\n",
       "     n_jobs=1, seeds=None)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.array(df.drop(['survived'], 1).astype(float))\n",
    "X = preprocessing.scale(X)\n",
    "y = np.array(df['survived'])\n",
    "\n",
    "clf = MeanShift()\n",
    "clf.fit(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now create a placeholder column for where we will be assigning a cluster group to each passenger. We will then iterate through each passenger and fill in the placeholder column by assigning them the appropriate cluster group. We will then count how many clusters the model created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "labels = clf.labels_\n",
    "cluster_centers = clf.cluster_centers_\n",
    "\n",
    "original_df['cluster_group'] = np.nan\n",
    "\n",
    "for i in range(len(X)):\n",
    "    original_df['cluster_group'].iloc[i] = labels[i]\n",
    "\n",
    "n_clusters_ = len(np.unique(labels))\n",
    "print(n_clusters_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We would like to check if the model's clusters reflect chances of survival in any way. Let's calculate survival rates per cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.37170263788968827\n",
      "1 1.0\n",
      "2 0.6818181818181818\n",
      "3 0.1\n"
     ]
    }
   ],
   "source": [
    "survival_rates = {}\n",
    "for i in range(n_clusters_):\n",
    "    temp_df = original_df[ (original_df['cluster_group']==float(i)) ]\n",
    "    survival_cluster = temp_df[  (temp_df['survived'] == 1) ]\n",
    "\n",
    "    survival_rate = len(survival_cluster) / len(temp_df)\n",
    "    print(i,survival_rate)\n",
    "    survival_rates[i] = survival_rate\n",
    "    \n",
    "#print(survival_rates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should now explore these clusters to see if we can get any valuable insight. We can do this by using a where clause, only pulling data from rows where the cluster group assigned matches what we want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     pclass  survived                                               name  \\\n",
      "1         1         1                     Allison, Master. Hudson Trevor   \n",
      "2         1         0                       Allison, Miss. Helen Loraine   \n",
      "3         1         0               Allison, Mr. Hudson Joshua Creighton   \n",
      "4         1         0    Allison, Mrs. Hudson J C (Bessie Waldo Daniels)   \n",
      "10        1         0                             Astor, Col. John Jacob   \n",
      "11        1         1  Astor, Mrs. John Jacob (Madeleine Talmadge Force)   \n",
      "16        1         0                           Baxter, Mr. Quigg Edmond   \n",
      "17        1         1    Baxter, Mrs. James (Helene DeLaudeniere Chaput)   \n",
      "23        1         1                              Bidois, Miss. Rosalie   \n",
      "24        1         1                                  Bird, Miss. Ellen   \n",
      "35        1         1                           Bowen, Miss. Grace Scott   \n",
      "66        1         1                        Chaudanson, Miss. Victorine   \n",
      "78        1         1  Compton, Mrs. Alexander Taylor (Mary Eliza Ing...   \n",
      "97        1         1  Douglas, Mrs. Frederick Charles (Mary Helene B...   \n",
      "103       1         1                      Endres, Miss. Caroline Louise   \n",
      "111       1         1                     Fortune, Miss. Alice Elizabeth   \n",
      "112       1         1                         Fortune, Miss. Ethel Flora   \n",
      "113       1         1                         Fortune, Miss. Mabel Helen   \n",
      "114       1         0                     Fortune, Mr. Charles Alexander   \n",
      "115       1         0                                  Fortune, Mr. Mark   \n",
      "116       1         1                Fortune, Mrs. Mark (Mary McDougald)   \n",
      "129       1         1                               Geiger, Miss. Amalie   \n",
      "139       1         1      Graham, Mrs. William Thompson (Edith Junkins)   \n",
      "173       1         0                                 Keeping, Mr. Edwin   \n",
      "192       1         1                               Lurette, Miss. Elise   \n",
      "193       1         1                  Madill, Miss. Georgette Alexandra   \n",
      "215       1         0                         Newell, Mr. Arthur Webster   \n",
      "238       1         1  Robert, Mrs. Edward Scott (Elisabeth Walton Mc...   \n",
      "249       1         1                        Ryerson, Master. John Borie   \n",
      "250       1         1                         Ryerson, Miss. Emily Borie   \n",
      "251       1         1              Ryerson, Miss. Susan Parker \"Suzette\"   \n",
      "252       1         0                         Ryerson, Mr. Arthur Larned   \n",
      "253       1         1    Ryerson, Mrs. Arthur Larned (Emily Maria Borie)   \n",
      "273       1         1                    Spedden, Master. Robert Douglas   \n",
      "274       1         1                       Spedden, Mr. Frederic Oakley   \n",
      "275       1         1  Spedden, Mrs. Frederic Oakley (Margaretta Corn...   \n",
      "285       1         0                                 Straus, Mr. Isidor   \n",
      "286       1         0             Straus, Mrs. Isidor (Rosalie Ida Blun)   \n",
      "308       1         1              White, Mrs. John Stuart (Ella Holmes)   \n",
      "309       1         1                           Wick, Miss. Mary Natalie   \n",
      "312       1         0                         Widener, Mr. George Dunton   \n",
      "313       1         0                          Widener, Mr. Harry Elkins   \n",
      "314       1         1       Widener, Mrs. George Dunton (Eleanor Elkins)   \n",
      "322       1         1                           Young, Miss. Marie Grice   \n",
      "\n",
      "        sex      age  sibsp  parch    ticket      fare            cabin  \\\n",
      "1      male   0.9167      1      2    113781  151.5500          C22 C26   \n",
      "2    female   2.0000      1      2    113781  151.5500          C22 C26   \n",
      "3      male  30.0000      1      2    113781  151.5500          C22 C26   \n",
      "4    female  25.0000      1      2    113781  151.5500          C22 C26   \n",
      "10     male  47.0000      1      0  PC 17757  227.5250          C62 C64   \n",
      "11   female  18.0000      1      0  PC 17757  227.5250          C62 C64   \n",
      "16     male  24.0000      0      1  PC 17558  247.5208          B58 B60   \n",
      "17   female  50.0000      0      1  PC 17558  247.5208          B58 B60   \n",
      "23   female  42.0000      0      0  PC 17757  227.5250              NaN   \n",
      "24   female  29.0000      0      0  PC 17483  221.7792              C97   \n",
      "35   female  45.0000      0      0  PC 17608  262.3750              NaN   \n",
      "66   female  36.0000      0      0  PC 17608  262.3750              B61   \n",
      "78   female  64.0000      0      2  PC 17756   83.1583              E45   \n",
      "97   female  27.0000      1      1  PC 17558  247.5208          B58 B60   \n",
      "103  female  38.0000      0      0  PC 17757  227.5250              C45   \n",
      "111  female  24.0000      3      2     19950  263.0000      C23 C25 C27   \n",
      "112  female  28.0000      3      2     19950  263.0000      C23 C25 C27   \n",
      "113  female  23.0000      3      2     19950  263.0000      C23 C25 C27   \n",
      "114    male  19.0000      3      2     19950  263.0000      C23 C25 C27   \n",
      "115    male  64.0000      1      4     19950  263.0000      C23 C25 C27   \n",
      "116  female  60.0000      1      4     19950  263.0000      C23 C25 C27   \n",
      "129  female  35.0000      0      0    113503  211.5000             C130   \n",
      "139  female  58.0000      0      1  PC 17582  153.4625             C125   \n",
      "173    male  32.5000      0      0    113503  211.5000             C132   \n",
      "192  female  58.0000      0      0  PC 17569  146.5208              B80   \n",
      "193  female  15.0000      0      1     24160  211.3375               B5   \n",
      "215    male  58.0000      0      2     35273  113.2750              D48   \n",
      "238  female  43.0000      0      1     24160  211.3375               B3   \n",
      "249    male  13.0000      2      2  PC 17608  262.3750  B57 B59 B63 B66   \n",
      "250  female  18.0000      2      2  PC 17608  262.3750  B57 B59 B63 B66   \n",
      "251  female  21.0000      2      2  PC 17608  262.3750  B57 B59 B63 B66   \n",
      "252    male  61.0000      1      3  PC 17608  262.3750  B57 B59 B63 B66   \n",
      "253  female  48.0000      1      3  PC 17608  262.3750  B57 B59 B63 B66   \n",
      "273    male   6.0000      0      2     16966  134.5000              E34   \n",
      "274    male  45.0000      1      1     16966  134.5000              E34   \n",
      "275  female  40.0000      1      1     16966  134.5000              E34   \n",
      "285    male  67.0000      1      0  PC 17483  221.7792          C55 C57   \n",
      "286  female  63.0000      1      0  PC 17483  221.7792          C55 C57   \n",
      "308  female  55.0000      0      0  PC 17760  135.6333              C32   \n",
      "309  female  31.0000      0      2     36928  164.8667               C7   \n",
      "312    male  50.0000      1      1    113503  211.5000              C80   \n",
      "313    male  27.0000      0      2    113503  211.5000              C82   \n",
      "314  female  50.0000      1      1    113503  211.5000              C80   \n",
      "322  female  36.0000      0      0  PC 17760  135.6333              C32   \n",
      "\n",
      "    embarked boat   body                           home.dest  cluster_group  \n",
      "1          S   11    NaN     Montreal, PQ / Chesterville, ON            2.0  \n",
      "2          S  NaN    NaN     Montreal, PQ / Chesterville, ON            2.0  \n",
      "3          S  NaN  135.0     Montreal, PQ / Chesterville, ON            2.0  \n",
      "4          S  NaN    NaN     Montreal, PQ / Chesterville, ON            2.0  \n",
      "10         C  NaN  124.0                        New York, NY            2.0  \n",
      "11         C    4    NaN                        New York, NY            2.0  \n",
      "16         C  NaN    NaN                        Montreal, PQ            2.0  \n",
      "17         C    6    NaN                        Montreal, PQ            2.0  \n",
      "23         C    4    NaN                                 NaN            2.0  \n",
      "24         S    8    NaN                                 NaN            2.0  \n",
      "35         C    4    NaN                     Cooperstown, NY            2.0  \n",
      "66         C    4    NaN                                 NaN            2.0  \n",
      "78         C   14    NaN                        Lakewood, NJ            2.0  \n",
      "97         C    6    NaN                        Montreal, PQ            2.0  \n",
      "103        C    4    NaN                        New York, NY            2.0  \n",
      "111        S   10    NaN                        Winnipeg, MB            2.0  \n",
      "112        S   10    NaN                        Winnipeg, MB            2.0  \n",
      "113        S   10    NaN                        Winnipeg, MB            2.0  \n",
      "114        S  NaN    NaN                        Winnipeg, MB            2.0  \n",
      "115        S  NaN    NaN                        Winnipeg, MB            2.0  \n",
      "116        S   10    NaN                        Winnipeg, MB            2.0  \n",
      "129        C    4    NaN                                 NaN            2.0  \n",
      "139        S    3    NaN                       Greenwich, CT            2.0  \n",
      "173        C  NaN   45.0                                 NaN            2.0  \n",
      "192        C  NaN    NaN                                 NaN            2.0  \n",
      "193        S    2    NaN                        St Louis, MO            2.0  \n",
      "215        C  NaN  122.0                       Lexington, MA            2.0  \n",
      "238        S    2    NaN                        St Louis, MO            2.0  \n",
      "249        C    4    NaN     Haverford, PA / Cooperstown, NY            2.0  \n",
      "250        C    4    NaN     Haverford, PA / Cooperstown, NY            2.0  \n",
      "251        C    4    NaN     Haverford, PA / Cooperstown, NY            2.0  \n",
      "252        C  NaN    NaN     Haverford, PA / Cooperstown, NY            2.0  \n",
      "253        C    4    NaN     Haverford, PA / Cooperstown, NY            2.0  \n",
      "273        C    3    NaN                     Tuxedo Park, NY            2.0  \n",
      "274        C    3    NaN                     Tuxedo Park, NY            2.0  \n",
      "275        C    3    NaN                     Tuxedo Park, NY            2.0  \n",
      "285        S  NaN   96.0                        New York, NY            2.0  \n",
      "286        S  NaN    NaN                        New York, NY            2.0  \n",
      "308        C    8    NaN  New York, NY / Briarcliff Manor NY            2.0  \n",
      "309        S    8    NaN                      Youngstown, OH            2.0  \n",
      "312        C  NaN    NaN                     Elkins Park, PA            2.0  \n",
      "313        C  NaN    NaN                     Elkins Park, PA            2.0  \n",
      "314        C    4    NaN                     Elkins Park, PA            2.0  \n",
      "322        C    8    NaN       New York, NY / Washington, DC            2.0  \n",
      "       pclass   survived        age      sibsp      parch        fare  \\\n",
      "count    44.0  44.000000  44.000000  44.000000  44.000000   44.000000   \n",
      "mean      1.0   0.681818  36.964016   0.795455   1.272727  208.069316   \n",
      "std       0.0   0.471155  17.847674   0.929605   1.107346   52.453703   \n",
      "min       1.0   0.000000   0.916700   0.000000   0.000000   83.158300   \n",
      "25%       1.0   0.000000  24.000000   0.000000   0.000000  151.550000   \n",
      "50%       1.0   1.000000  36.000000   1.000000   1.000000  221.779200   \n",
      "75%       1.0   1.000000  50.000000   1.000000   2.000000  262.375000   \n",
      "max       1.0   1.000000  67.000000   3.000000   4.000000  263.000000   \n",
      "\n",
      "             body  cluster_group  \n",
      "count    5.000000           44.0  \n",
      "mean   104.400000            2.0  \n",
      "std     36.156604            0.0  \n",
      "min     45.000000            2.0  \n",
      "25%     96.000000            2.0  \n",
      "50%    122.000000            2.0  \n",
      "75%    124.000000            2.0  \n",
      "max    135.000000            2.0  \n"
     ]
    }
   ],
   "source": [
    "print(original_df[(original_df['cluster_group']==2)])\n",
    "print(original_df[(original_df['cluster_group']==2)].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can create separate dataframes using the same logic to separate clusters. From there, we can get even more specific, for example, 1st class passangers in cluster 2. With this info, we can see that 1st class passengers in cluster 2 had a 68% survival rate. Breaking this down further and finding what caused this clustering could then give us some valuable insight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pclass</th>\n",
       "      <th>survived</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>body</th>\n",
       "      <th>cluster_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>44.0</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>44.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>36.964016</td>\n",
       "      <td>0.795455</td>\n",
       "      <td>1.272727</td>\n",
       "      <td>208.069316</td>\n",
       "      <td>104.400000</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.471155</td>\n",
       "      <td>17.847674</td>\n",
       "      <td>0.929605</td>\n",
       "      <td>1.107346</td>\n",
       "      <td>52.453703</td>\n",
       "      <td>36.156604</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.916700</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>83.158300</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>151.550000</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>221.779200</td>\n",
       "      <td>122.000000</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>262.375000</td>\n",
       "      <td>124.000000</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>263.000000</td>\n",
       "      <td>135.000000</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       pclass   survived        age      sibsp      parch        fare  \\\n",
       "count    44.0  44.000000  44.000000  44.000000  44.000000   44.000000   \n",
       "mean      1.0   0.681818  36.964016   0.795455   1.272727  208.069316   \n",
       "std       0.0   0.471155  17.847674   0.929605   1.107346   52.453703   \n",
       "min       1.0   0.000000   0.916700   0.000000   0.000000   83.158300   \n",
       "25%       1.0   0.000000  24.000000   0.000000   0.000000  151.550000   \n",
       "50%       1.0   1.000000  36.000000   1.000000   1.000000  221.779200   \n",
       "75%       1.0   1.000000  50.000000   1.000000   2.000000  262.375000   \n",
       "max       1.0   1.000000  67.000000   3.000000   4.000000  263.000000   \n",
       "\n",
       "             body  cluster_group  \n",
       "count    5.000000           44.0  \n",
       "mean   104.400000            2.0  \n",
       "std     36.156604            0.0  \n",
       "min     45.000000            2.0  \n",
       "25%     96.000000            2.0  \n",
       "50%    122.000000            2.0  \n",
       "75%    124.000000            2.0  \n",
       "max    135.000000            2.0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_2 = original_df[(original_df['cluster_group']==2)]\n",
    "cluster_2_fc = cluster_2[(cluster_2['pclass']==1)]\n",
    "cluster_2_fc.describe()\n",
    "#This shows that the first class passengers in cluster 2 had a 70% survival rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may have noticed group 1 has a 100% survival rate, and group 3's survival rate was as low as 10%. As we can see, the model was able to group the passengers in a way that can help us determine what factors led to death or survival, all without us programming it to do so."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
